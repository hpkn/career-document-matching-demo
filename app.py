# app.py

import os
import json
import uuid
from pathlib import Path
from typing import List, Dict, Any
import streamlit as st
import pandas as pd
from config import PDF_DIR, DATA_DIR, INDEX_DIR
from ingest import build_index, find_tech_page, ocr_page
from rag import get_raw_project_data, extract_tech_data_from_ocr
from semantic_normalizer import normalize_project, normalize_tech_data_df
from rules_engine import apply_all_checkbox_rules
from report_utils import (
    group_rules_by_category,
    build_project_summary_text,
    get_form_layout,
    get_project_calculations_as_json
)

# --- Session State Initialization ---------------------------------
# This is the core of the new 3-step logic
if "step" not in st.session_state:
    st.session_state.step = 1
if "rudf_file_processed" not in st.session_state:
    st.session_state.rudf_file_processed = False
if "rudf_projects_df" not in st.session_state:
    st.session_state.rudf_projects_df = None
if "tech_file_path" not in st.session_state:
    st.session_state.tech_file_path = None
if "tech_projects_df" not in st.session_state:
    st.session_state.tech_projects_df = None
if "final_projects_df" not in st.session_state:
    st.session_state.final_projects_df = None
if "run_id" not in st.session_state:
    st.session_state.run_id = str(uuid.uuid4()) # Used to create unique index folders per run

st.set_page_config(page_title="ê²½ë ¥ì¸ì • ìë™ì™„ì„± ë°ëª¨", layout="wide")
st.title("ê²½ë ¥ì¸ì • ìë™ì™„ì„± Demo")

# --- Helper Functions -------------------------------------------
def reset_session():
    """Resets the entire session state to start over."""
    st.session_state.step = 1
    st.session_state.rudf_file_processed = False
    st.session_state.rudf_projects_df = None
    st.session_state.tech_file_path = None
    st.session_state.tech_projects_df = None
    st.session_state.final_projects_df = None
    st.session_state.run_id = str(uuid.uuid4())
    # We don't clear the data/pdfs or index here, as a new run_id creates a new path

# --- Main App UI --------------------------------------------------

# Use columns for layout
col1, col2 = st.columns([1, 2])

# --- [COLUMN 1] - Sidebar / Control Panel ---
with col1:
    st.header("ì²˜ë¦¬ ë‹¨ê³„")
    if st.button(" ì²˜ìŒë¶€í„° ë‹¤ì‹œ ì‹œì‘ (Reset)"):
        reset_session()
        st.experimental_rerun()

    # --- STEP 1: RUDF Upload (NO OCR) -----------------------------
    with st.expander("Step 1: RUDF íŒŒì¼ ì—…ë¡œë“œ (OCR ì—†ìŒ)", expanded=(st.session_state.step == 1)):
        st.markdown("""
        ë©”ì¸ ê²½ë ¥ ì¦ëª…ì„œ íŒŒì¼ì„ ì—…ë¡œë“œí•©ë‹ˆë‹¤.
        ì´ ë‹¨ê³„ëŠ” **OCRì„ ì‚¬ìš©í•˜ì§€ ì•Šê³ ** í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ì—¬ **'ê²°ê³¼ 1'** (ì²´í¬ë°•ìŠ¤ ê°€ì´ë“œ)ì„ ìƒì„±í•©ë‹ˆë‹¤.
        """)
        
        uploaded_rudf_file = st.file_uploader(
            "RUDF íŒŒì¼ (ê²½ë ¥ ì¦ëª…ì„œ)",
            type=["pdf"],
            accept_multiple_files=False,
            key="rudf_uploader"
        )

        if uploaded_rudf_file and not st.session_state.rudf_file_processed:
            with st.spinner("Step 1: RUDF íŒŒì¼ì„ ì²˜ë¦¬í•˜ê³  AI ë©”ëª¨ë¦¬ ìƒì„± ì¤‘ (OCR ì—†ìŒ)..."):
                
                # Create a unique index path for this run
                index_folder_name = f"faiss_index_rudf_{st.session_state.run_id}"
                
                # Save the file
                file_ext = Path(uploaded_rudf_file.name).suffix
                save_name = f"{uuid.uuid4().hex}{file_ext}"
                save_path = PDF_DIR / save_name
                with open(save_path, "wb") as f:
                    f.write(uploaded_rudf_file.read())
                
                file_map = {save_name: uploaded_rudf_file.name}

                # Build FAISS index *without* OCR
                build_index(file_map, index_folder_name, use_ocr=False)

                # Run RAG to get data for 'ê²°ê³¼ 1'
                query = "ê¸°ìˆ ê²½ë ¥ ë° ê±´ì„¤ì‚¬ì—…ê´€ë¦¬ ê²½ë ¥ í…Œì´ë¸”ì—ì„œ ëª¨ë“  í”„ë¡œì íŠ¸ ì¶”ì¶œ"
                raw_project_data = get_raw_project_data(query, top_k=50, index_folder_name=index_folder_name)

                if raw_project_data:
                    # Normalize and apply rules
                    all_projects_rules = []
                    for raw_project in raw_project_data:
                        normalized_project = normalize_project(raw_project) # Use original normalize
                        project_rules_series = apply_all_checkbox_rules(normalized_project)
                        all_projects_rules.append(project_rules_series)
                    
                    st.session_state.rudf_projects_df = pd.DataFrame(all_projects_rules)
                    st.session_state.rudf_file_processed = True
                    st.session_state.step = 2
                    st.experimental_rerun()
                else:
                    st.error("RUDF íŒŒì¼ì—ì„œ í”„ë¡œì íŠ¸ ë°ì´í„°ë¥¼ ì¶”ì¶œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

    # --- STEP 2: ê¸°ìˆ ê²½ë ¥ Upload (WITH OCR) -----------------------
    with st.expander("Step 2: ê¸°ìˆ ê²½ë ¥ íŒŒì¼ ì—…ë¡œë“œ (OCR)", expanded=(st.session_state.step == 2)):
        st.markdown("""
        '1. ê¸°ìˆ ê²½ë ¥' í…Œì´ë¸”ì´ í¬í•¨ëœ ìƒì„¸ PDF íŒŒì¼ì„ ì—…ë¡œë“œí•©ë‹ˆë‹¤.
        ì´ ë‹¨ê³„ëŠ” í•´ë‹¹ í˜ì´ì§€ë§Œ **OCRë¡œ ì²˜ë¦¬**í•˜ì—¬ í”„ë¡œì íŠ¸ ëª©ë¡ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.
        """)
        
        uploaded_tech_file = st.file_uploader(
            "'1. ê¸°ìˆ ê²½ë ¥' PDF íŒŒì¼",
            type=["pdf"],
            accept_multiple_files=False,
            key="tech_uploader"
        )
        
        if uploaded_tech_file:
            with st.spinner("Step 2: '1. ê¸°ìˆ ê²½ë ¥' í˜ì´ì§€ë¥¼ ì°¾ì•„ OCRë¡œ ì²˜ë¦¬í•˜ëŠ” ì¤‘..."):
                # Save the file
                file_ext = Path(uploaded_tech_file.name).suffix
                save_name = f"{uuid.uuid4().hex}{file_ext}"
                save_path = PDF_DIR / save_name
                with open(save_path, "wb") as f:
                    f.write(uploaded_tech_file.read())
                
                st.session_state.tech_file_path = str(save_path)

                # 1. Find the target page
                page_num = find_tech_page(st.session_state.tech_file_path)
                
                # 2. OCR only that page
                ocr_text = ocr_page(st.session_state.tech_file_path, page_num)
                
                # 3. Extract data from the OCR'd text
                raw_tech_data = extract_tech_data_from_ocr(ocr_text)

                if raw_tech_data:
                    # Convert to DataFrame and store in session state
                    df = pd.DataFrame(raw_tech_data)
                    
                    # Rename columns to match the user's requested table headers
                    column_map = {
                        "start_date": "ì°¸ì—¬ê¸°ê°„ (ì‹œì‘ì¼)",
                        "end_date": "ì°¸ì—¬ê¸°ê°„ (ì¢…ë£Œì¼)",
                        "recognition_days": "ì¸ì •ì¼",
                        "project_name": "ì‚¬ì—…ëª…",
                        "job_field": "ì§ë¬´ë¶„ì•¼",
                        "role": "ë‹´ë‹¹ì—…ë¬´",
                        "client": "ë°œì£¼ì | ê³µì‚¬ì¢…ë¥˜",
                        "position": "ì§ìœ„"
                    }
                    df_display = df.rename(columns=column_map)
                    
                    # Ensure all requested columns are present
                    display_headers = ["ì°¸ì—¬ê¸°ê°„ (ì‹œì‘ì¼)", "ì°¸ì—¬ê¸°ê°„ (ì¢…ë£Œì¼)", "ì¸ì •ì¼", "ì‚¬ì—…ëª…", "ì§ë¬´ë¶„ì•¼", "ë‹´ë‹¹ì—…ë¬´", "ë°œì£¼ì | ê³µì‚¬ì¢…ë¥˜", "ì§ìœ„"]
                    for col in display_headers:
                        if col not in df_display.columns:
                            df_display[col] = "N/A"
                    
                    st.session_state.tech_projects_df = df[column_map.keys()] # Store with original keys
                    st.session_state.step = 3
                    st.experimental_rerun()
                else:
                    st.error("'1. ê¸°ìˆ ê²½ë ¥' í…Œì´ë¸”ì—ì„œ ë°ì´í„°ë¥¼ ì¶”ì¶œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

# --- [COLUMN 2] - Main Display Area ---
with col2:
    if st.session_state.step == 1:
        st.info("Step 1: ì¢Œì¸¡ì—ì„œ RUDF íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.")
    
    # --- Display for Step 1 Results / Step 2 Prompt ---
    if st.session_state.step >= 2:
        st.header("ê²°ê³¼ 1: ê²½ë ¥ì¸ì • ê°€ì´ë“œ ìë™ ì²´í¬ (RUDF ê¸°ì¤€)")
        st.caption(f"ì´ {len(st.session_state.rudf_projects_df)}ê°œì˜ í”„ë¡œì íŠ¸ê°€ RUDF íŒŒì¼ì—ì„œ ì¶”ì¶œë˜ì—ˆìŠµë‹ˆë‹¤. ì•„ë˜ëŠ” ì²« ë²ˆì§¸ í”„ë¡œì íŠ¸ì˜ ìë™ ì²´í¬ ê²°ê³¼ì…ë‹ˆë‹¤.")
        
        # Render Checkbox Guide (same as your old code)
        project_rules_series = st.session_state.rudf_projects_df.iloc[0]
        form_layout = get_form_layout()
        grouped_rules = group_rules_by_category()
        
        def render_checkbox_row(checked: bool, label: str) -> str:
            box = "â˜‘" if checked else "â˜"
            return f"{box} {label}"

        st.markdown("---")
        for section_key, section in form_layout.items():
            st.markdown(f"#### ğŸ§¾ {section['title']}")
            for q in section["questions"]:
                st.markdown(f"**{q['title']}**")
                options = q["options"]
                num_cols = min(len(options), 4)
                cols = st.columns(num_cols)
                for i, opt in enumerate(options):
                    col = cols[i % num_cols]
                    rid = opt["rule_id"]
                    col_name = f"rule__{rid}"
                    checked = bool(project_rules_series.get(col_name, False))
                    with col:
                        st.markdown(render_checkbox_row(checked, opt["label"]))
                st.markdown("")
        
        st.markdown("---")
        if st.session_state.step == 2:
            st.info("Step 2: ì¢Œì¸¡ì—ì„œ '1. ê¸°ìˆ ê²½ë ¥' PDF íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.")
            
    # --- Display for Step 2 Results / Step 3 Prompt ---
    if st.session_state.step == 3:
        st.header("Step 2: OCR ì¶”ì¶œ ê²°ê³¼ (ê¸°ìˆ ê²½ë ¥)")
        st.caption("'1. ê¸°ìˆ ê²½ë ¥' í˜ì´ì§€ì—ì„œ OCRë¡œ ì¶”ì¶œëœ ë°ì´í„°ì…ë‹ˆë‹¤.")
        
        # Display the table with the requested headers
        df_display = st.session_state.tech_projects_df.rename(columns={
            "start_date": "ì°¸ì—¬ê¸°ê°„ (ì‹œì‘ì¼)",
            "end_date": "ì°¸ì—¬ê¸°ê°„ (ì¢…ë£Œì¼)",
            "recognition_days": "ì¸ì •ì¼",
            "project_name": "ì‚¬ì—…ëª…",
            "job_field": "ì§ë¬´ë¶„ì•¼",
            "role": "ë‹´ë‹¹ì—…ë¬´",
            "client": "ë°œì£¼ì | ê³µì‚¬ì¢…ë¥˜",
            "position": "ì§ìœ„"
        })
        st.dataframe(df_display)
        
        if st.button("Step 3: ìµœì¢… ì‚°ì¶œë¬¼ ìƒì„±"):
            with st.spinner("Step 3: ìµœì¢… ì‚°ì¶œë¬¼ì„ ìƒì„±í•˜ëŠ” ì¤‘..."):
                # Normalize the data from STEP 2
                st.session_state.final_projects_df = normalize_tech_data_df(st.session_state.tech_projects_df)
                st.session_state.step = 4 # Move to final step
                st.experimental_rerun()
                
    # --- Display for Step 3 Results ---
    if st.session_state.step == 4:
        st.header("Step 3: ìµœì¢… ì‚°ì¶œë¬¼ (Form í¬ë§·)")
        st.caption("Step 2ì—ì„œ ì¶”ì¶œëœ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìµœì¢… ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í–ˆìŠµë‹ˆë‹¤.")
        
        try:
            # Generate the final JSON report using the Step 2 data
            json_data = get_project_calculations_as_json(st.session_state.final_projects_df)
            
            career_history = json_data.get("participating_engineer_career_history", {})
            job_history = json_data.get("participating_engineer_job_field_history", {})

            # --- 1. ì°¸ì—¬ê¸°ìˆ ì¸ ê²½ë ¥ ì‚¬í•­ (Render Final Report) ---
            st.subheader("ğŸ“‹ " + career_history.get("title", "ì°¸ì—¬ê¸°ìˆ ì¸ ê²½ë ¥ ì‚¬í•­"))

            header = career_history.get("header", {})
            col1, col2, col3, col4, col5 = st.columns(5)
            col1.metric("êµ¬ë¶„", header.get("division", ""))
            col2.metric("ì„±ëª…", header.get("name", ""))
            col3.metric("ë¶„ì•¼", header.get("field", ""))
            col4.metric("í˜„ì¬ê¹Œì§€ ê²½ë ¥", header.get("total_career", ""))
            col5.metric("í‰ì ", header.get("score", ""))

            st.markdown("---")

            # Relevant field (100%)
            relevant_section = career_history.get("relevant_field_section", {})
            st.markdown(f"### âœ… {relevant_section.get('section_title', 'í•´ë‹¹ë¶„ì•¼')} ({relevant_section.get('career_period', '')})")
            relevant_projects = relevant_section.get("projects", [])
            if relevant_projects:
                st.dataframe(pd.DataFrame(relevant_projects), use_container_width=True, hide_index=True)
                subtotal = relevant_section.get("subtotal", {})
                st.caption(f"**{subtotal.get('text', 'ì†Œê³„')}**: {subtotal.get('calculation', '')}")
            else:
                st.info("í•´ë‹¹ ë¶„ì•¼ ì‹¤ì ì´ ì—†ìŠµë‹ˆë‹¤.")

            st.markdown("---")

            # Other field (60%)
            other_section = career_history.get("other_field_section", {})
            st.markdown(f"### âšª {other_section.get('section_title', 'í•´ë‹¹ë¶„ì•¼ ì´ì™¸')} ({other_section.get('career_period', '')})")
            other_projects = other_section.get("projects", [])
            if other_projects:
                st.dataframe(pd.DataFrame(other_projects), use_container_width=True, hide_index=True)
                subtotal = other_section.get("subtotal", {})
                st.caption(f"**{subtotal.get('text', 'ì†Œê³„')}**: {subtotal.get('calculation', '')}")
            else:
                st.info("í•´ë‹¹ ë¶„ì•¼ ì´ì™¸ ì‹¤ì ì´ ì—†ìŠµë‹ˆë‹¤.")

            st.markdown("---")

            # Total
            total = career_history.get("total", {})
            st.markdown(f"### ğŸ“Š {total.get('text', 'í•©ê³„')}")
            col1, col2 = st.columns(2)
            col1.metric("ì´ ê²½ë ¥", total.get("career", ""))
            col2.metric("ê³„ì‚°", total.get("calculation", ""))

            # --- 2. ì°¸ì—¬ê¸°ìˆ ì¸ ì§ë¬´ë¶„ì•¼ ì‹¤ì  ---
            st.markdown("---")
            st.subheader("ğŸ“‹ " + job_history.get("title", "ì°¸ì—¬ê¸°ìˆ ì¸ ì§ë¬´ë¶„ì•¼ ì‹¤ì "))
            st.caption(job_history.get("subtitle", ""))

            # Evaluation 1
            eval1 = job_history.get("evaluation_1", {})
            eval1_header = eval1.get("header", {})
            st.markdown(f"### í‰ê°€ 1 ({eval1_header.get('score', '6ì ')})")
            c1, c2, c3, c4 = st.columns(4)
            c1.metric("êµ¬ë¶„", eval1_header.get("division", ""))
            c2.metric("ì„±ëª…", eval1_header.get("name", ""))
            c3.metric("í˜„ì¬ê¹Œì§€ ê²½ë ¥", eval1_header.get("total_career", ""))
            c4.metric("í‰ì ", eval1_header.get("score", ""))
            st.markdown(f"**ì§ë¬´ë¶„ì•¼**: {eval1_header.get('job_fields', '')}")
            eval1_projects = eval1.get("projects", [])
            if eval1_projects:
                st.dataframe(pd.DataFrame(eval1_projects), use_container_width=True, hide_index=True)
                total1 = eval1.get("total", {})
                st.caption(f"**{total1.get('text', 'ê³„')}**: {total1.get('calculation', '')}")

            st.markdown("---")

            # Evaluation 2
            eval2 = job_history.get("evaluation_2", {})
            eval2_header = eval2.get("header", {})
            st.markdown(f"### í‰ê°€ 2 ({eval2_header.get('score', '3ì ')})")
            c1, c2, c3, c4 = st.columns(4)
            c1.metric("êµ¬ë¶„", eval2_header.get("division", ""))
            c2.metric("ì„±ëª…", eval2_header.get("name", ""))
            c3.metric("í˜„ì¬ê¹Œì§€ ê²½ë ¥", eval2_header.get("total_career", ""))
            c4.metric("í‰ì ", eval2_header.get("score", ""))
            st.markdown(f"**ì§ë¬´ë¶„ì•¼**: {eval2_header.get('job_fields', '')}")
            st.caption("â€» ì„¤ê³„ ì œì™¸")
            eval2_projects = eval2.get("projects", [])
            if eval2_projects:
                st.dataframe(pd.DataFrame(eval2_projects), use_container_width=True, hide_index=True)
                total2 = eval2.get("total", {})
                st.caption(f"**{total2.get('text', 'ê³„')}**: {total2.get('calculation', '')}")

            # --- 3. JSON Download Button ---
            st.markdown("---")
            st.subheader("ğŸ“¥ JSON ë‹¤ìš´ë¡œë“œ")
            json_string = json.dumps(json_data, ensure_ascii=False, indent=2)
            st.download_button(
                label="ğŸ“¥ ê²½ë ¥ ì‚¬í•­ JSON ë‹¤ìš´ë¡œë“œ",
                data=json_string,
                file_name="ê²½ë ¥ì¸ì •_ê²°ê³¼.json",
                mime="application/json",
            )
            with st.expander("JSON ë¯¸ë¦¬ë³´ê¸°"):
                st.json(json_data)

        except Exception as e:
            st.error(f"ìµœì¢… ì‚°ì¶œë¬¼ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            import traceback
            st.error(traceback.format_exc())