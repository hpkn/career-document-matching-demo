# rag.py
import json
from typing import List, Dict, Any

import requests
from langchain_community.vectorstores import FAISS
from langchain_community.embeddings import HuggingFaceEmbeddings

from config import INDEX_DIR, OLLAMA_BASE_URL, OLLAMA_MODEL


def _load_vectorstore() -> FAISS:
    """
    Load the FAISS index created by ingest.py.
    """
    print(f"[RAG] Loading FAISS index from: {INDEX_DIR}")
    embeddings = HuggingFaceEmbeddings(
        model_name="jhgan/ko-sroberta-multitask",
        model_kwargs={"device": "cpu"},
    )
    vectorstore = FAISS.load_local(
        folder_path=str(INDEX_DIR),
        embeddings=embeddings,
        allow_dangerous_deserialization=True,  # OK for local demo
    )
    return vectorstore


def _call_ollama(prompt: str) -> str:
    """
    Call a local Ollama model via HTTP and return the text response.
    """
    url = f"{OLLAMA_BASE_URL}/api/chat"

    payload = {
        "model": OLLAMA_MODEL,
        "messages": [
            {"role": "user", "content": prompt}
        ],
        "stream": False,
        "options": {
            "temperature": 0.0  # make it as deterministic as possible
        },
    }

    print(f"[RAG] Calling Ollama at {url} with model '{OLLAMA_MODEL}'...")
    resp = requests.post(url, json=payload)
    resp.raise_for_status()
    data = resp.json()

    text = data.get("message", {}).get("content", "")
    return text.strip()


def get_raw_facts(query: str, top_k: int = 5) -> List[Dict[str, Any]]:
    """
    Main RAG function:
        1. Search FAISS index with the query.
        2. Take top_k chunks as context.
        3. Ask Ollama to extract project history as structured JSON.

    Returns: List of project dicts.
    """
    vectorstore = _load_vectorstore()

    print(f"[RAG] Searching for top {top_k} chunks for query: {query!r}")
    docs = vectorstore.similarity_search(query, k=top_k)

    if not docs:
        print("[RAG] No documents found in vector store for this query.")
        return []

    context_text = "\n\n---\n\n".join(
        f"[CHUNK {i+1}]\n{d.page_content}"
        for i, d in enumerate(docs)
    )

    # ðŸ’¡ IMPORTANT:
    # We request all fields that your CHECKBOX_RULES might use:
    # - project_name, client, role, original_field, start/end dates
    # - participation_date / recognition_date / use_date_type
    # - recognition_rate_rule, specialty, duty_field1/2, tech_eval_method, etc.
    prompt = f"""
        ë‹¹ì‹ ì€ í•œêµ­ ê±´ì„¤/í† ëª© ê²½ë ¥ ì„œë¥˜ë¥¼ ì½ê³  **ì •í˜•í™”ëœ í”„ë¡œì íŠ¸ ì´ë ¥**ì„ ë½‘ì•„ì£¼ëŠ” ë„ìš°ë¯¸ìž…ë‹ˆë‹¤.

        ì•„ëž˜ëŠ” ì—¬ëŸ¬ ê°œì˜ ë¬¸ì„œì—ì„œ ë½‘ì€ ê´€ë ¨ í…ìŠ¤íŠ¸ìž…ë‹ˆë‹¤.  
        ì´ í…ìŠ¤íŠ¸ë§Œì„ ê·¼ê±°ë¡œ í”„ë¡œì íŠ¸ ê²½ë ¥ ì •ë³´ë¥¼ JSON ë°°ì—´ë¡œ ì •ë¦¬í•´ ì£¼ì„¸ìš”.

        [ì»¨í…ìŠ¤íŠ¸ ì‹œìž‘]
        {context_text}
        [ì»¨í…ìŠ¤íŠ¸ ë]

        ìš”êµ¬ì‚¬í•­:
        - ìœ„ ì»¨í…ìŠ¤íŠ¸ì— ë“±ìž¥í•˜ëŠ” í”„ë¡œì íŠ¸/ê³µì‚¬ ê²½ë ¥ì„ ì°¾ì•„ì„œ JSON ë°°ì—´ë¡œ ì¶œë ¥í•©ë‹ˆë‹¤.
        - ê° í”„ë¡œì íŠ¸ í•­ëª©ì€ ì•„ëž˜ í•„ë“œë¥¼ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤. (ëª¨ë¥¼ ê²½ìš° null í—ˆìš©)

        í•„ë“œ ì •ì˜:
        - "project_name": string ë˜ëŠ” null
            - ì‚¬ì—…ëª… / ê³µì‚¬ëª…
        - "client": string ë˜ëŠ” null
            - ë°œì£¼ì²˜ (êµ­ê°€, ì§€ë°©ìžì¹˜ë‹¨ì²´, OOì‹œì²­, ë¯¼ê°„íšŒì‚¬ ë“±)
        - "start_date": string ë˜ëŠ” null
            - ì°¸ì—¬ ì‹œìž‘ì¼
        - "end_date": string ë˜ëŠ” null
            - ì°¸ì—¬ ì¢…ë£Œì¼
        - "original_field": string ë˜ëŠ” null
            - ì›ëž˜ ê³µì¢…/ë¶„ì•¼ (ì˜ˆ: "ë„ë¡œ", "í•˜ì²œ", "ìƒìˆ˜ë„", "í•˜ìˆ˜ë„", "ì² ë„", "ë‹¨ì§€", "í•­ë§Œ", "êµ°ë¶€ëŒ€ì‹œì„¤", "ì¡°ê²½", "ê¸°íƒ€í† ëª©", "ì „ë ¥êµ¬", "ê³µí•­" ë“±)
        - "role": string ë˜ëŠ” null
            - ë‹´ë‹¹ì—…ë¬´ (ì˜ˆ: "ì‹œê³µ", "ê°ë¦¬", "ê±´ì„¤ì‚¬ì—…ê´€ë¦¬(ìƒì£¼)", "ê±´ì„¤ì‚¬ì—…ê´€ë¦¬(ê¸°ìˆ ì§€ì›)", "ì„¤ê³„", "ìœ ì§€ê´€ë¦¬" ë“±)
        - "participation_date": string ë˜ëŠ” null
            - ì°¸ì—¬ì¼ (í•„ìš”í•˜ë©´ start_dateì™€ ë™ì¼í•˜ê²Œ ë‘˜ ìˆ˜ ìžˆìŒ)
        - "recognition_date": string ë˜ëŠ” null
            - ì¸ì •ì¼ (í•„ìš”í•˜ë©´ end_dateì™€ ë™ì¼í•˜ê²Œ ë‘˜ ìˆ˜ ìžˆìŒ)
        - "use_date_type": string ë˜ëŠ” null
            - ê²½ë ¥ í‰ê°€ ì‹œ ì‚¬ìš©í•  ê¸°ì¤€.
            - "participation" ë˜ëŠ” "recognition" ì¤‘ í•˜ë‚˜ë¥¼ ì¶”ì²œí•˜ê±°ë‚˜, íŒë‹¨ì´ ì–´ë ¤ìš°ë©´ null.
        - "recognition_rate_rule": string ë˜ëŠ” null
            - ê²½ë ¥ ì¸ì • ë¹„ìœ¨ íŒë‹¨ì— í•„ìš”í•œ ížŒíŠ¸. ì˜ˆ:
                - "civil_60" (í† ëª©ë¶„ì•¼(ì²´í¬ê³µì¢…ì œì™¸)60%)
                - "track_60", "track_40"
                - "civil_etc_60" ë“±
            ì»¨í…ìŠ¤íŠ¸ì—ì„œ ë¹„ìœ¨ ê´€ë ¨ ë‹¨ì„œê°€ ì—†ìœ¼ë©´ null.
        - "specialty": string ë˜ëŠ” null
            - ê¸°ìˆ ì§€ì› í•´ë‹¹ë¶„ì•¼ì—ì„œ ì‚¬ìš©í•  ì „ë¬¸ë¶„ì•¼ (ì˜ˆ: "ë„ë¡œë°ê³µí•­", "í† ëª©êµ¬ì¡°", "í† ì§ˆì§€ì§ˆ", "ê±´ì„¤ì•ˆì „", "ì¡°ê²½ê³„íš", "í•­ë§Œë°í•´ì•ˆ", ...)
        - "tech_eval_method": string ë˜ëŠ” null
            - ê¸°ìˆ ì§€ì› í‰ê°€ ë°©ë²•.
            - ì˜ˆ: "same_as_sangju" (ìƒì£¼ í‰ê°€ ë°©ì‹ê³¼ ë™ì¼), "use_specialty" (ì°¸ì—¬ë¶„ì•¼ì˜ ì „ë¬¸ë¶„ì•¼ ìž‘ì„±) ë“±.
        - "duty_field1": string ë˜ëŠ” null
            - ìƒì£¼ ì§ë¬´ë¶„ì•¼1 í‰ê°€ì— ì‚¬ìš©í•  ì§ë¬´ë¶„ì•¼ (ì˜ˆ: "í† ëª©", "ê±´ì¶•", "ê¸°ê³„", "ì•ˆì „ê´€ë¦¬" ë“±)
        - "duty_field1_eval_method": string ë˜ëŠ” null
            - ì§ë¬´ë¶„ì•¼1 í‰ê°€ ë°©ë²•. ì˜ˆ:
                - "by_duty" (ì§ë¬´ë¶„ì•¼ë¡œ í‰ê°€)
                - "same_as_sangju" (ìƒì£¼ í•´ë‹¹ë¶„ì•¼ í‰ê°€ ë°©ì‹ê³¼ ë™ì¼)
        - "duty_field1_recognition_rule": string ë˜ëŠ” null
            - ì§ë¬´ë¶„ì•¼1 ê²½ë ¥ ì¸ì • ê¸°ì¤€. ì˜ˆ:
                - "include_blank_field"
                - "include_blank_duty"
                - "only_filled"
        - "duty_field2": string ë˜ëŠ” null
            - ìƒì£¼ ì§ë¬´ë¶„ì•¼2 í‰ê°€ì— ì‚¬ìš©í•  ì§ë¬´ë¶„ì•¼ (ì˜ˆ: "í† ëª©", "ê±´ì¶•", "ê¸°ê³„", "ì¡°ê²½", "ì•ˆì „ê´€ë¦¬" ë“±)
        - "duty_field2_eval_method": string ë˜ëŠ” null
        - "duty_field2_recognition_rule": string ë˜ëŠ” null
        - "raw_text": string
            - í•´ë‹¹ í”„ë¡œì íŠ¸ ê²½ë ¥ì„ ì„¤ëª…í•˜ëŠ” ì›ë¬¸ í…ìŠ¤íŠ¸ ìš”ì•½ (ì¶œì²˜ ë¬¸ìž¥ì„ ê·¸ëŒ€ë¡œ ì“°ê±°ë‚˜ ìš”ì•½ ê°€ëŠ¥)

        ì¶œë ¥ í˜•ì‹(ë§¤ìš° ì¤‘ìš”):
        - ë°˜ë“œì‹œ **JSON ë°°ì—´**ë§Œ ì¶œë ¥í•˜ì„¸ìš”.
        - ë§ˆí¬ë‹¤ìš´(````json`, ````, `###` ë“±) ì ˆëŒ€ ê¸ˆì§€.
        - ìžì—°ì–´ ì„¤ëª… ë¬¸ìž¥ ê¸ˆì§€.
        - "..."(ìƒëžµ ê¸°í˜¸) ì‚¬ìš© ê¸ˆì§€. ëª¨ë¥´ëŠ” ê°’ì€ nullë¡œ ë‘ì„¸ìš”.
        - ìµœëŒ€ 10ê°œ í•­ëª©ê¹Œì§€ë§Œ ì¶œë ¥.

        ì˜ˆì‹œ í˜•ì‹ (ì˜ˆì‹œëŠ” ì„¤ëª…ìš©ì´ë©°, ì‹¤ì œ ê°’ì€ ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ìœ¼ë¡œ ì±„ìš°ì„¸ìš”):

        [
        {{
            "project_name": "OO ë„ë¡œ í™•í¬ìž¥ ê³µì‚¬",
            "client": "ì„œìš¸íŠ¹ë³„ì‹œ OOêµ¬ì²­",
            "start_date": "2019-01-01",
            "end_date": "2020-06-30",
            "original_field": "ë„ë¡œ",
            "role": "ì‹œê³µ",
            "participation_date": "2019-01-01",
            "recognition_date": "2020-06-30",
            "use_date_type": "participation",
            "recognition_rate_rule": "civil_60",
            "specialty": null,
            "tech_eval_method": null,
            "duty_field1": "í† ëª©",
            "duty_field1_eval_method": "by_duty",
            "duty_field1_recognition_rule": "only_filled",
            "duty_field2": null,
            "duty_field2_eval_method": null,
            "duty_field2_recognition_rule": null,
            "raw_text": "ì„œìš¸íŠ¹ë³„ì‹œ OOêµ¬ì²­ ë°œì£¼ ë„ë¡œ í™•í¬ìž¥ ê³µì‚¬ì— ì‹œê³µ ê¸°ìˆ ìžë¡œ ì°¸ì—¬..."
        }}
        ]

        ìœ„ ì˜ˆì‹œëŠ” í˜•ì‹ë§Œ ì°¸ê³ í•˜ì„¸ìš”. ì‹¤ì œ ê²°ê³¼ëŠ” ì»¨í…ìŠ¤íŠ¸ì— ê¸°ë°˜í•˜ì—¬ ìž‘ì„±í•´ì•¼ í•©ë‹ˆë‹¤.
    """

    raw_text = _call_ollama(prompt)

    # Some models still try to add explanation or extra text.
    # We try to isolate the JSON array by looking for the first "[" and last "]".
    sanitized = raw_text.strip()
    first_bracket = sanitized.find("[")
    last_bracket = sanitized.rfind("]")

    if first_bracket != -1 and last_bracket != -1 and last_bracket > first_bracket:
        sanitized = sanitized[first_bracket : last_bracket + 1]

    # Just in case the model still put "..." somewhere, replace them with null
    sanitized = sanitized.replace("...", "null")

    try:
        data = json.loads(sanitized)
        # If it's a single dict instead of a list, wrap it
        if isinstance(data, dict):
            data = [data]
        if not isinstance(data, list):
            raise ValueError("Parsed JSON is not a list.")
        # Filter out any None items
        data = [item for item in data if item is not None]
    except Exception as e:
        print("[RAG] Failed to parse JSON from Ollama. Raw output:")
        print(raw_text)
        print("[RAG] Sanitized attempt:")
        print(sanitized)
        raise e

    print(f"[RAG] Parsed {len(data)} project items from Ollama.")
    return data
